{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, intermediate_channels, stride=1, identity=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.identity = identity\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=intermediate_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(intermediate_channels)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=intermediate_channels,\n",
    "            out_channels=intermediate_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(intermediate_channels)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=intermediate_channels,\n",
    "            out_channels=intermediate_channels * 4,\n",
    "            kernel_size=1,\n",
    "            padding=0,\n",
    "            stride=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(intermediate_channels * 4)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.identity:\n",
    "            identity = x.clone()\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        if self.identity:\n",
    "            x += identity\n",
    "            \n",
    "        out = self.relu3(x)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResidualBlock, layers, img_channels, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=img_channels,\n",
    "            out_channels=64,\n",
    "            kernel_size=7,\n",
    "            stride=2,\n",
    "            padding=3\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.layer1 = self._make_layer(ResidualBlock, layers[0], 64, stride=1)\n",
    "        self.layer2 = self._make_layer(ResidualBlock, layers[1], 128, stride=2)\n",
    "        self.layer3 = self._make_layer(ResidualBlock, layers[2], 256, stride=2)\n",
    "        self.layer4 = self._make_layer(ResidualBlock, layers[3], 512, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=7)\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "\n",
    "    \n",
    "    def _make_layer(self, ResidualBlock, num_residual_blocks, intermediate_channels, stride):\n",
    "\n",
    "        layers = []\n",
    "\n",
    "\n",
    "        layers += [ResidualBlock(self.in_channels, intermediate_channels, stride)]\n",
    "\n",
    "        self.in_channels = intermediate_channels * 4\n",
    "\n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers += [ResidualBlock(self.in_channels, intermediate_channels, identity=True)]\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "    \n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        out = self.fc(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,472\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "             ReLU-13          [-1, 256, 56, 56]               0\n",
      "    ResidualBlock-14          [-1, 256, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "           Conv2d-18           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-19           [-1, 64, 56, 56]             128\n",
      "             ReLU-20           [-1, 64, 56, 56]               0\n",
      "           Conv2d-21          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-22          [-1, 256, 56, 56]             512\n",
      "             ReLU-23          [-1, 256, 56, 56]               0\n",
      "    ResidualBlock-24          [-1, 256, 56, 56]               0\n",
      "           Conv2d-25           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-26           [-1, 64, 56, 56]             128\n",
      "             ReLU-27           [-1, 64, 56, 56]               0\n",
      "           Conv2d-28           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-29           [-1, 64, 56, 56]             128\n",
      "             ReLU-30           [-1, 64, 56, 56]               0\n",
      "           Conv2d-31          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-32          [-1, 256, 56, 56]             512\n",
      "             ReLU-33          [-1, 256, 56, 56]               0\n",
      "    ResidualBlock-34          [-1, 256, 56, 56]               0\n",
      "           Conv2d-35          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-36          [-1, 128, 56, 56]             256\n",
      "             ReLU-37          [-1, 128, 56, 56]               0\n",
      "           Conv2d-38          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-39          [-1, 128, 28, 28]             256\n",
      "             ReLU-40          [-1, 128, 28, 28]               0\n",
      "           Conv2d-41          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-42          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-43          [-1, 512, 28, 28]               0\n",
      "    ResidualBlock-44          [-1, 512, 28, 28]               0\n",
      "           Conv2d-45          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-46          [-1, 128, 28, 28]             256\n",
      "             ReLU-47          [-1, 128, 28, 28]               0\n",
      "           Conv2d-48          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-49          [-1, 128, 28, 28]             256\n",
      "             ReLU-50          [-1, 128, 28, 28]               0\n",
      "           Conv2d-51          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-52          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-53          [-1, 512, 28, 28]               0\n",
      "    ResidualBlock-54          [-1, 512, 28, 28]               0\n",
      "           Conv2d-55          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 128, 28, 28]             256\n",
      "             ReLU-57          [-1, 128, 28, 28]               0\n",
      "           Conv2d-58          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-59          [-1, 128, 28, 28]             256\n",
      "             ReLU-60          [-1, 128, 28, 28]               0\n",
      "           Conv2d-61          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-62          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-63          [-1, 512, 28, 28]               0\n",
      "    ResidualBlock-64          [-1, 512, 28, 28]               0\n",
      "           Conv2d-65          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 128, 28, 28]             256\n",
      "             ReLU-67          [-1, 128, 28, 28]               0\n",
      "           Conv2d-68          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-69          [-1, 128, 28, 28]             256\n",
      "             ReLU-70          [-1, 128, 28, 28]               0\n",
      "           Conv2d-71          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-72          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-73          [-1, 512, 28, 28]               0\n",
      "    ResidualBlock-74          [-1, 512, 28, 28]               0\n",
      "           Conv2d-75          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-76          [-1, 256, 28, 28]             512\n",
      "             ReLU-77          [-1, 256, 28, 28]               0\n",
      "           Conv2d-78          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-79          [-1, 256, 14, 14]             512\n",
      "             ReLU-80          [-1, 256, 14, 14]               0\n",
      "           Conv2d-81         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-82         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-83         [-1, 1024, 14, 14]               0\n",
      "    ResidualBlock-84         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-85          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-86          [-1, 256, 14, 14]             512\n",
      "             ReLU-87          [-1, 256, 14, 14]               0\n",
      "           Conv2d-88          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-89          [-1, 256, 14, 14]             512\n",
      "             ReLU-90          [-1, 256, 14, 14]               0\n",
      "           Conv2d-91         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-92         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-93         [-1, 1024, 14, 14]               0\n",
      "    ResidualBlock-94         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-95          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-96          [-1, 256, 14, 14]             512\n",
      "             ReLU-97          [-1, 256, 14, 14]               0\n",
      "           Conv2d-98          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-99          [-1, 256, 14, 14]             512\n",
      "            ReLU-100          [-1, 256, 14, 14]               0\n",
      "          Conv2d-101         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-102         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-103         [-1, 1024, 14, 14]               0\n",
      "   ResidualBlock-104         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-105          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-106          [-1, 256, 14, 14]             512\n",
      "            ReLU-107          [-1, 256, 14, 14]               0\n",
      "          Conv2d-108          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-109          [-1, 256, 14, 14]             512\n",
      "            ReLU-110          [-1, 256, 14, 14]               0\n",
      "          Conv2d-111         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-112         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-113         [-1, 1024, 14, 14]               0\n",
      "   ResidualBlock-114         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-115          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-116          [-1, 256, 14, 14]             512\n",
      "            ReLU-117          [-1, 256, 14, 14]               0\n",
      "          Conv2d-118          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-119          [-1, 256, 14, 14]             512\n",
      "            ReLU-120          [-1, 256, 14, 14]               0\n",
      "          Conv2d-121         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-122         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-123         [-1, 1024, 14, 14]               0\n",
      "   ResidualBlock-124         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-125          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-126          [-1, 256, 14, 14]             512\n",
      "            ReLU-127          [-1, 256, 14, 14]               0\n",
      "          Conv2d-128          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-129          [-1, 256, 14, 14]             512\n",
      "            ReLU-130          [-1, 256, 14, 14]               0\n",
      "          Conv2d-131         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-132         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-133         [-1, 1024, 14, 14]               0\n",
      "   ResidualBlock-134         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-135          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-136          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-137          [-1, 512, 14, 14]               0\n",
      "          Conv2d-138            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-139            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-140            [-1, 512, 7, 7]               0\n",
      "          Conv2d-141           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-142           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-143           [-1, 2048, 7, 7]               0\n",
      "   ResidualBlock-144           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-145            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-146            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-147            [-1, 512, 7, 7]               0\n",
      "          Conv2d-148            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-149            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-150            [-1, 512, 7, 7]               0\n",
      "          Conv2d-151           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-152           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-153           [-1, 2048, 7, 7]               0\n",
      "   ResidualBlock-154           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-155            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-156            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-157            [-1, 512, 7, 7]               0\n",
      "          Conv2d-158            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-159            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-160            [-1, 512, 7, 7]               0\n",
      "          Conv2d-161           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-162           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-163           [-1, 2048, 7, 7]               0\n",
      "   ResidualBlock-164           [-1, 2048, 7, 7]               0\n",
      "       AvgPool2d-165           [-1, 2048, 1, 1]               0\n",
      "          Linear-166                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 22,780,520\n",
      "Trainable params: 22,780,520\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 263.59\n",
      "Params size (MB): 86.90\n",
      "Estimated Total Size (MB): 351.06\n",
      "----------------------------------------------------------------\n",
      "torch.Size([10, 1000])\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = ResNet(ResidualBlock, [3, 4, 6, 3], img_channels=3, num_classes=1000).to(device)\n",
    "x = torch.randn(10, 3, 224, 224).to(device)\n",
    "\n",
    "writer = SummaryWriter()\n",
    "writer.add_graph(model, x.to(device))\n",
    "\n",
    "summary(model, (3, 224, 224))\n",
    "\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe0011ce67a31b72ba55fb8e7bb9d2ac2b6ebade09aef517c89167728047b0fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
